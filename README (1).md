# InterprÃ©tabilitÃ© des Clauses Contractuelles

## ğŸ“Œ Objectif

Ce projet vise Ã  construire un modÃ¨le de Machine Learning capable de dÃ©terminer automatiquement si une clause contractuelle extraite dâ€™un contrat dâ€™assurance est **interprÃ©table** (formulation floue ou ambigÃ¼e) ou **non-interprÃ©table** (formulation claire).

---

## ğŸ“ DonnÃ©es

Les donnÃ©es proviennent de trois sources :
- Clauses interprÃ©tables du **MÃ©diateur de lâ€™assurance**,
- Clauses non-interprÃ©tables extraites de **contrats PDF de Pacifica**,
- Clauses gÃ©nÃ©rÃ©es manuellement.

Le jeu de donnÃ©es final contient **596 lignes** et **3 colonnes** :
- `clauses` : texte brut de la clause,
- `interpretabilite` : 1 (interprÃ©table) ou 0 (non-interprÃ©table),
- `clauses_vect` : clause nettoyÃ©e.

Un dÃ©sÃ©quilibre de classes a Ã©tÃ© corrigÃ© avec **SMOTE**.

---

## ğŸ”„ Pipeline

1. **Nettoyage du texte** : suppression HTML, stopwords, lemmatisation.
2. **Vectorisation** : avec Word2Vec.
3. **Ã‰quilibrage des classes** : avec SMOTE.
4. **ModÃ©lisation** : plusieurs algorithmes ont Ã©tÃ© testÃ©s.
5. **Ã‰valuation** : mÃ©triques classiques (f1-score, ROC AUC, matrice de confusion).

---

## ğŸ¤– ModÃ¨les testÃ©s

- RÃ©gression logistique
- Random Forest
- Gradient Boosting
- XGBoost (meilleur rÃ©sultat)
- SVM

---

## ğŸ§ª RÃ©sultats

- Le modÃ¨le **XGBoost** a obtenu les meilleures performances sur le jeu de test.
- Les modÃ¨les dÃ©tectent bien les clauses non-interprÃ©tables, mais ont plus de mal avec les clauses interprÃ©tables.
- La faible quantitÃ© de donnÃ©es reste une limite.

---

## ğŸ§° Librairies utilisÃ©es

- `pandas`, `numpy`
- `scikit-learn`
- `xgboost`
- `nltk`, `gensim`
- `imblearn`
- `matplotlib`, `seaborn`

---

## â–¶ï¸ Lancer le projet

1. Cloner le dÃ©pÃ´t  
2. Installer les dÃ©pendances  
3. Ouvrir le notebook `interpretabilite_clauses.ipynb`  
4. ExÃ©cuter les cellules dans lâ€™ordre