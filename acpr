import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, StratifiedGroupKFold
from sklearn.metrics import classification_report, roc_auc_score, f1_score, confusion_matrix
from lightgbm import LGBMClassifier
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline

# Étape 1 : Préparation des données
df = df_all_trim_final.copy()
df["CONTRAT"] = df["CONTRAT"].astype(str)
df["SINISTRE_BINARY"] = df["SINISTRE"].astype(int)

# Split contrat : train_val vs test
contracts_df = df.groupby("CONTRAT").agg({"SINISTRE_BINARY": "max"}).reset_index()
train_val_ids, test_ids = train_test_split(
    contracts_df["CONTRAT"],
    test_size=0.2,
    stratify=contracts_df["SINISTRE_BINARY"],
    random_state=42
)

df_train_val = df[df["CONTRAT"].isin(train_val_ids)]
df_test = df[df["CONTRAT"].isin(test_ids)]

# Étape 2 : Définir X, y, groups
X = df_train_val.drop(columns=["SINISTRE", "SINISTRE_BINARY", "TRIM_YEAR", "CONTRAT", "INSEE_COM", "NOMBRE_SINISTRES"])
X = X.loc[:, ~X.columns.duplicated()]  # Supprimer les colonnes dupliquées
y = df_train_val["SINISTRE_BINARY"]
groups = df_train_val["CONTRAT"]

# Étape 3 : Cross-validation par contrat
sgkf = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=42)
folds = list(sgkf.split(X, y, groups=groups))
train_val_idx = np.concatenate([val_idx for _, val_idx in folds[:3]])
val_idx = folds[3][1]

# Étape 4 : Sélection des variables importantes (par seuil d’importance)
def select_top_features_by_importance(model, X, threshold=0.005):
    importances = model.feature_importances_
    return X.columns[importances > threshold].tolist()

seuils_importance = [0.0005, 0.001, 0.002, 0.005, 0.01]
resultats = []

for seuil in seuils_importance:
    print(f"\n🔎 Seuil importance : {seuil}")

    model_lgbm = LGBMClassifier(random_state=42, n_jobs=-1)
    model_lgbm.fit(X.iloc[train_val_idx], y.iloc[train_val_idx])

    selected_features = select_top_features_by_importance(model_lgbm, X, seuil)

    X_train_sel = X.iloc[train_val_idx][selected_features]
    y_train_sel = y.iloc[train_val_idx]
    X_val_sel = X.iloc[val_idx][selected_features]
    y_val_sel = y.iloc[val_idx]

    pipe = Pipeline([
        ("smote", SMOTE(random_state=42)),
        ("under", RandomUnderSampler(random_state=42)),
        ("clf", LGBMClassifier(random_state=42, n_jobs=-1))
    ])

    pipe.fit(X_train_sel, y_train_sel)
    y_val_proba = pipe.predict_proba(X_val_sel)[:, 1]

    best_f1 = 0
    best_thresh = 0.5
    for t in np.arange(0.01, 1.0, 0.01):
        y_val_pred = (y_val_proba >= t).astype(int)
        f1 = f1_score(y_val_sel, y_val_pred)
        if f1 > best_f1:
            best_f1 = f1
            best_thresh = t

    resultats.append({
        "seuil_var": seuil,
        "n_features": len(selected_features),
        "best_threshold": best_thresh,
        "best_f1": best_f1,
        "features": selected_features
    })

# Étape 5 : Sélection du meilleur seuil
results_df = pd.DataFrame(resultats)
best_row = results_df.sort_values(by="best_f1", ascending=False).iloc[0]

# Étape 6 : Réentraînement + évaluation sur TEST
X_train_final = X.iloc[train_val_idx][best_row["features"]]
y_train_final = y.iloc[train_val_idx]

X_test = df_test.drop(columns=["SINISTRE", "SINISTRE_BINARY", "TRIM_YEAR", "CONTRAT", "INSEE_COM", "NOMBRE_SINISTRES"])
X_test = X_test.loc[:, ~X_test.columns.duplicated()]  # Supprimer les colonnes dupliquées
X_test_final = X_test[best_row["features"]]
y_test_final = df_test["SINISTRE_BINARY"]

final_pipeline = Pipeline([
    ("smote", SMOTE(random_state=42)),
    ("under", RandomUnderSampler(random_state=42)),
    ("clf", LGBMClassifier(random_state=42, n_jobs=-1))
])

final_pipeline.fit(X_train_final, y_train_final)
y_test_proba = final_pipeline.predict_proba(X_test_final)[:, 1]
y_test_pred = (y_test_proba >= best_row["best_threshold"]).astype(int)

# Résultats
print("\n📊 Évaluation finale sur le TEST :")
print("Confusion matrix :")
print(confusion_matrix(y_test_final, y_test_pred))
print("\nClassification report :")
print(classification_report(y_test_final, y_test_pred, digits=4))
print(f"AUC : {roc_auc_score(y_test_final, y_test_proba):.4f}")
print(f"F1-score : {f1_score(y_test_final, y_test_pred):.4f}")

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

# Courbe ROC
fpr, tpr, thresholds = roc_curve(y_test_final, y_test_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color="darkorange", lw=2, label=f"ROC curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], color="navy", lw=2, linestyle="--", label="Random Classifier")
plt.xlabel("Taux de faux positifs (FPR)")
plt.ylabel("Taux de vrais positifs (TPR)")
plt.title("Courbe ROC – LightGBM")
plt.legend(loc="lower right")
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

from sklearn.model_selection import RandomizedSearchCV
from lightgbm import LGBMClassifier
from imblearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.metrics import make_scorer, f1_score
import numpy as np

# 1. Définir le pipeline
pipeline = Pipeline([
    ("smote", SMOTE(random_state=42)),
    ("under", RandomUnderSampler(random_state=42)),
    ("clf", LGBMClassifier(random_state=42, n_jobs=-1))
])

# 2. Paramètres à tester (nombre réduit pour rapidité)
param_dist = {
    "clf__n_estimators": [100, 200],
    "clf__learning_rate": [0.05, 0.1, 0.2],
    "clf__num_leaves": [15, 31, 50],
    "clf__max_depth": [-1, 5, 10],
    "clf__min_child_samples": [10, 20, 30],
    "clf__subsample": [0.6, 0.8, 1.0],
    "clf__colsample_bytree": [0.6, 0.8, 1.0]
}

# 3. Définir le RandomizedSearchCV
random_search = RandomizedSearchCV(
    estimator=pipeline,
    param_distributions=param_dist,
    n_iter=20,  # nombre d’échantillons testés (ajuste à 10 si tu veux encore plus rapide)
    scoring=make_scorer(f1_score),
    cv=3,
    verbose=2,
    random_state=42,
    n_jobs=-1
)

# 4. Entraînement rapide sur le train
random_search.fit(X_train_final, y_train_final)

# 5. Meilleurs hyperparamètres
print("\n Meilleurs hyperparamètres trouvés :")
print(random_search.best_params_)

# 6. Prédiction
y_test_proba = random_search.predict_proba(X_test_final)[:, 1]

# 7. Optimisation du seuil
best_thresh, best_f1 = 0.5, 0
for t in np.arange(0.01, 1.0, 0.01):
    f1 = f1_score(y_test_final, (y_test_proba >= t).astype(int))
    if f1 > best_f1:
        best_f1 = f1
        best_thresh = t

print(f"\n Seuil optimal : {best_thresh:.2f} | F1-score : {best_f1:.4f}")
