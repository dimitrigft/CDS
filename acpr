import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, StratifiedGroupKFold
from sklearn.metrics import classification_report, f1_score, roc_auc_score, confusion_matrix
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline
from xgboost import XGBClassifier

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ã‰tape 1 : Split des donnÃ©es par contrat (train/val/test)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df = df_all_trim_final.copy()
df["CONTRAT"] = df["CONTRAT"].astype(str)
df["SINISTRE_BINARY"] = df["SINISTRE"].astype(int)

contracts_df = df.groupby("CONTRAT")["SINISTRE_BINARY"].max().reset_index()

train_val_ids, test_ids = train_test_split(
    contracts_df["CONTRAT"],
    test_size=0.2,
    stratify=contracts_df["SINISTRE_BINARY"],
    random_state=42
)

df_train_val = df[df["CONTRAT"].isin(train_val_ids)]
df_test = df[df["CONTRAT"].isin(test_ids)]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ã‰tape 2 : Cross-validation sur les folds
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
X = df_train_val.drop(columns=["SINISTRE", "SINISTRE_BINARY", "TRIM_YEAR", "CONTRAT", "INSEE_COM", "NOMBRE_SINISTRES"])
y = df_train_val["SINISTRE_BINARY"]
groups = df_train_val["CONTRAT"]

sgkf = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=42)
folds = list(sgkf.split(X, y, groups))

train_val_idx = np.concatenate([val_idx for _, val_idx in folds[:3]])
val_idx = folds[3][1]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ã‰tape 3 : SÃ©lection automatique des variables via importance
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_top_features(model, X, threshold):
    importances = model.feature_importances_
    return X.columns[importances > threshold].tolist()

seuils = [0.0005, 0.001, 0.002, 0.005, 0.01]
results = []

for seuil in seuils:
    model = XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric="logloss", random_state=42)
    model.fit(X.iloc[train_val_idx], y.iloc[train_val_idx])

    top_feats = get_top_features(model, X, threshold=seuil)
    X_train_sel = X.iloc[train_val_idx][top_feats]
    y_train_sel = y.iloc[train_val_idx]
    X_val_sel = X.iloc[val_idx][top_feats]
    y_val_sel = y.iloc[val_idx]

    pipe = Pipeline([
        ("smote", SMOTE(random_state=42)),
        ("under", RandomUnderSampler(random_state=42)),
        ("clf", XGBClassifier(
            objective="binary:logistic",
            use_label_encoder=False,
            eval_metric="logloss",
            n_estimators=100,
            random_state=42,
            n_jobs=-1
        ))
    ])
    pipe.fit(X_train_sel, y_train_sel)
    y_val_proba = pipe.predict_proba(X_val_sel)[:, 1]

    best_f1 = 0
    best_thresh = 0.5
    for t in np.arange(0.01, 1.0, 0.01):
        y_pred = (y_val_proba >= t).astype(int)
        f1 = f1_score(y_val_sel, y_pred)
        if f1 > best_f1:
            best_f1 = f1
            best_thresh = t

    results.append({
        "seuil": seuil,
        "features": top_feats,
        "f1": best_f1,
        "threshold": best_thresh,
        "n_features": len(top_feats)
    })

results_df = pd.DataFrame(results)
best_row = results_df.sort_values(by="f1", ascending=False).iloc[0]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ã‰tape 4 : SMOTE + Undersampling sur donnÃ©es finales
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
X_train_final = X.iloc[train_val_idx][best_row["features"]]
y_train_final = y.iloc[train_val_idx]

X_test = df_test.drop(columns=["SINISTRE", "SINISTRE_BINARY", "TRIM_YEAR", "CONTRAT", "INSEE_COM", "NOMBRE_SINISTRES"])
y_test = df_test["SINISTRE_BINARY"]
X_test_final = X_test[best_row["features"]]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ã‰tape 5 : EntraÃ®nement final + optimisation du seuil
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
final_pipe = Pipeline([
    ("smote", SMOTE(random_state=42)),
    ("under", RandomUnderSampler(random_state=42)),
    ("clf", XGBClassifier(
        objective="binary:logistic",
        use_label_encoder=False,
        eval_metric="logloss",
        n_estimators=100,
        random_state=42,
        n_jobs=-1
    ))
])

final_pipe.fit(X_train_final, y_train_final)
y_test_proba = final_pipe.predict_proba(X_test_final)[:, 1]

# Optimisation du seuil
best_thresh = best_row["threshold"]
y_test_pred = (y_test_proba >= best_thresh).astype(int)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ã‰tape 6 : Ã‰valuation finale sur le jeu de test
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print(f"\nðŸ“Š Seuil de dÃ©cision optimisÃ© : {best_thresh:.2f}")
print("Confusion matrix :")
print(confusion_matrix(y_test, y_test_pred))
print("\nClassification report :")
print(classification_report(y_test, y_test_pred, digits=4))
print(f"AUC : {roc_auc_score(y_test, y_test_proba):.4f}")
print(f"F1-score : {f1_score(y_test, y_test_pred):.4f}")
