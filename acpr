from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import make_scorer
from catboost import CatBoostClassifier

# Pipeline pour RandomizedSearchCV
opt_pipe = Pipeline([
    ("smote", SMOTE(random_state=42)),
    ("under", RandomUnderSampler(random_state=42)),
    ("clf", CatBoostClassifier(verbose=0, random_state=42))
])

# Grille d'hyperparamètres
param_grid = {
    "clf__iterations": [100, 200, 300],
    "clf__learning_rate": [0.01, 0.05, 0.1],
    "clf__depth": [4, 6, 8],
    "clf__l2_leaf_reg": [1, 3, 5, 7],
    "clf__border_count": [32, 64, 128]
}

# Optimisation
search = RandomizedSearchCV(
    estimator=opt_pipe,
    param_distributions=param_grid,
    scoring=make_scorer(f1_score),
    n_iter=20,  # Ajuste selon les ressources
    cv=3,
    verbose=2,
    n_jobs=-1,
    random_state=42
)

search.fit(X_train_final, y_train_final)

# Meilleurs hyperparamètres
print("\n Meilleurs paramètres trouvés :")
print(search.best_params_)

# Évaluation
y_test_proba = search.predict_proba(X_test_final)[:, 1]
best_f1 = 0
best_thresh = 0.5
for t in np.arange(0.01, 1.0, 0.01):
    f1 = f1_score(y_test_final, (y_test_proba >= t).astype(int))
    if f1 > best_f1:
        best_f1 = f1
        best_thresh = t

print(f"\nSeuil optimal : {best_thresh:.2f} | F1-score : {best_f1:.4f}")
