from sklearn.model_selection import train_test_split

df_all_trim_final["CONTRAT"] = df_all_trim_final["CONTRAT"].astype(str)
df_all_trim_final["SINISTRE_BINARY"] = df_all_trim_final["SINISTRE"].astype(int)

# AgrÃ©gation au niveau contrat
contracts_df = df_all_trim_final.groupby("CONTRAT").agg({
    "SINISTRE_BINARY": "max"
}).reset_index()

# Split stratifiÃ© au niveau contrat
train_val_ids, test_ids = train_test_split(
    contracts_df["CONTRAT"],
    test_size=0.2,
    stratify=contracts_df["SINISTRE_BINARY"],
    random_state=42
)

df_train_val = df_all_trim_final[df_all_trim_final["CONTRAT"].isin(train_val_ids)]
df_test = df_all_trim_final[df_all_trim_final["CONTRAT"].isin(test_ids)]



------------------

from sklearn.model_selection import StratifiedGroupKFold

X = df_train_val.drop(columns=["SINISTRE", "SINISTRE_BINARY", "TRIM_YEAR", "CONTRAT", "INSEE_COM", "NOMBRE_SINISTRES"])
y = df_train_val["SINISTRE_BINARY"]
groups = df_train_val["CONTRAT"]

sgkf = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=42)
folds = list(sgkf.split(X, y, groups))

# Index total pour entraÃ®nement final
train_val_idx = np.concatenate([val_idx for _, val_idx in folds[:3]])
val_idx = folds[3][1]  # dernier fold = validation

-------------------


from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, classification_report

results_val = []
models = []

for fold, (train_idx, val_idx_fold) in enumerate(folds):
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx_fold]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx_fold]

    model = RandomForestClassifier(n_estimators=100, class_weight="balanced", random_state=42, n_jobs=-1)
    model.fit(X_train, y_train)

    y_pred = model.predict(X_val)
    y_proba = model.predict_proba(X_val)[:, 1]

    results_val.append({
        'fold': fold,
        'f1': f1_score(y_val, y_pred),
        'auc': roc_auc_score(y_val, y_proba)
    })
    models.append(model)


----------------

def select_top_features_by_importance(model, X, threshold=0.005):
    importances = model.feature_importances_
    selected_features = X.columns[importances > threshold]
    return selected_features.tolist()

best_model_idx = max(range(len(results_val)), key=lambda i: results_val[i]['f1'])
best_model = models[best_model_idx]
selected_features = select_top_features_by_importance(best_model, X, threshold=0.005)

-----------------

X_train_final = X.iloc[train_val_idx][selected_features]
y_train_final = y.iloc[train_val_idx]

X_test = df_test.drop(columns=["SINISTRE", "SINISTRE_BINARY", "TRIM_YEAR", "CONTRAT", "INSEE_COM", "NOMBRE_SINISTRES"])
y_test = df_test["SINISTRE_BINARY"]
X_test_final = X_test[selected_features]
y_test_final = y_test

model_final = RandomForestClassifier(n_estimators=100, class_weight="balanced", random_state=42, n_jobs=-1)
model_final.fit(X_train_final, y_train_final)

y_pred_test = model_final.predict(X_test_final)
y_proba_test = model_final.predict_proba(X_test_final)[:, 1]

print("\nðŸ“Š Ã‰valuation finale sur le TEST :")
print(classification_report(y_test_final, y_pred_test, digits=4))
print(f"AUC : {roc_auc_score(y_test_final, y_proba_test):.4f}")
print(f"F1-score : {f1_score(y_test_final, y_pred_test):.4f}")
