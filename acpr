from imblearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import classification_report, roc_auc_score, f1_score
from scipy.stats import randint

# Pipeline : SMOTE + undersampling + RandomForest
pipeline = Pipeline([
    ('smote', SMOTE(random_state=42)),
    ('under', RandomUnderSampler(random_state=42)),
    ('clf', RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1))
])

# Param√®tres √† tester (limit√©s pour rapidit√©)
param_dist = {
    'clf__n_estimators': randint(80, 150),
    'clf__max_depth': [None, 10, 20],
    'clf__min_samples_split': [2, 5],
    'clf__min_samples_leaf': [1, 2],
    'clf__max_features': ['sqrt', 'log2']
}

# RandomizedSearch rapide
search = RandomizedSearchCV(
    estimator=pipeline,
    param_distributions=param_dist,
    n_iter=10,            # Limit√© √† 10 essais
    scoring='f1',
    cv=3,                 # Seulement 3 folds
    verbose=1,
    random_state=42,
    n_jobs=-1             # Pour aller plus vite
)

# Entra√Ænement
search.fit(X_train_final, y_train_final)

# Meilleur mod√®le
best_model = search.best_estimator_
print("‚úÖ Best params:", search.best_params_)

# Pr√©diction sur le test
y_pred_test = best_model.predict(X_test_final)
y_proba_test = best_model.predict_proba(X_test_final)[:, 1]

print("\nüìä R√©sultats sur le TEST :")
print(classification_report(y_test_final, y_pred_test, digits=4))
print(f"AUC : {roc_auc_score(y_test_final, y_proba_test):.4f}")
print(f"F1-score : {f1_score(y_test_final, y_pred_test):.4f}")
