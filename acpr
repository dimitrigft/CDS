from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import SelectFromModel
from sklearn.pipeline import Pipeline
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.metrics import classification_report, f1_score, roc_auc_score, confusion_matrix
import numpy as np

# 1. SÃ©lection des variables importantes (par L1)
selector = SelectFromModel(LogisticRegression(penalty="l1", solver="liblinear", random_state=42), threshold="mean")

# 2. Pipeline complet avec Ã©quilibrage
pipeline = ImbPipeline([
    ("feature_selection", selector),
    ("smote", SMOTE(random_state=42)),
    ("under", RandomUnderSampler(random_state=42)),
    ("clf", LogisticRegression(penalty="l2", class_weight="balanced", solver="liblinear", random_state=42))
])

# 3. EntraÃ®nement
pipeline.fit(X_train_final, y_train_final)

# 4. ProbabilitÃ©s pour seuil optimisÃ©
y_val_proba = pipeline.predict_proba(X_test_final)[:, 1]

# Optimisation du seuil
meilleur_seuil = 0.5
meilleur_f1 = 0

for seuil in np.arange(0.01, 1.0, 0.01):
    y_val_pred = (y_val_proba >= seuil).astype(int)
    f1 = f1_score(y_test_final, y_val_pred)
    if f1 > meilleur_f1:
        meilleur_f1 = f1
        meilleur_seuil = seuil

print(f"\nðŸ” Meilleur seuil trouvÃ© : {meilleur_seuil:.2f} avec F1-score : {meilleur_f1:.4f}")

y_test_pred = (y_val_proba >= meilleur_seuil).astype(int)

print("\nðŸ“Š Ã‰valuation finale - RÃ©gression logistique optimisÃ©e :")
print("Confusion matrix :")
print(confusion_matrix(y_test_final, y_test_pred))
print("\nClassification report :")
print(classification_report(y_test_final, y_test_pred, digits=4))
print(f"AUC : {roc_auc_score(y_test_final, y_val_proba):.4f}")
print(f"F1-score optimisÃ© : {f1_score(y_test_final, y_test_pred):.4f}")
